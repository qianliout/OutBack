### **PyTorch ä¸­çš„ `BatchNorm` ç³»åˆ—å‡½æ•°è¯¦è§£**

åœ¨ PyTorch ä¸­ï¼Œ`BatchNorm` ç”¨äºå¯¹æ•°æ®è¿›è¡Œæ‰¹é‡è§„èŒƒåŒ–ï¼ˆBatch Normalizationï¼‰ï¼Œä¸»è¦åŒ…å«ä¸‰ç§ç±»å‹ï¼š

1.  **`nn.BatchNorm1d`**ï¼šç”¨äº **1D æ•°æ®**ï¼ˆå¦‚å…¨è¿æ¥å±‚æˆ–æ—¶åºæ•°æ®ï¼‰ã€‚
2.  **`nn.BatchNorm2d`**ï¼šç”¨äº **2D æ•°æ®**ï¼ˆå¦‚å›¾åƒæ•°æ®ï¼ŒCNN ä¸­æœ€å¸¸ç”¨ï¼‰ã€‚
3.  **`nn.BatchNorm3d`**ï¼šç”¨äº **3D æ•°æ®**ï¼ˆå¦‚è§†é¢‘æˆ– 3D åŒ»å­¦å›¾åƒï¼‰ã€‚

å®ƒä»¬çš„æ ¸å¿ƒåŒºåˆ«åœ¨äº **è¾“å…¥æ•°æ®çš„ç»´åº¦** å’Œ **å½’ä¸€åŒ–çš„æ–¹å¼**ã€‚ä¸‹é¢è¯¦ç»†è§£é‡Šå®ƒä»¬çš„ä¸åŒåŠä¼ å‚çš„åŒºåˆ«ã€‚

***

## **1. `nn.BatchNorm1d`ï¼ˆ1D æ‰¹é‡è§„èŒƒåŒ–ï¼‰**

### **é€‚ç”¨åœºæ™¯**

*   **å…¨è¿æ¥å±‚ï¼ˆFCï¼‰** çš„è¾“å‡ºã€‚
*   **æ—¶åºæ•°æ®**ï¼ˆå¦‚ RNN/LSTM çš„éšè—çŠ¶æ€ï¼‰ã€‚
*   **1D ç‰¹å¾å›¾**ï¼ˆå¦‚éŸ³é¢‘ä¿¡å·æˆ–ä¼ æ„Ÿå™¨æ•°æ®ï¼‰ã€‚

### **è¾“å…¥æ•°æ®æ ¼å¼**

*   **Shape**: `(batch_size, num_features)` æˆ– `(batch_size, num_features, sequence_length)`ã€‚
*   **å½’ä¸€åŒ–ç»´åº¦**ï¼šå¯¹ `num_features` çš„æ¯ä¸ªç‰¹å¾å•ç‹¬è®¡ç®—å‡å€¼å’Œæ–¹å·®ã€‚

### **ç¤ºä¾‹**

```python
import torch
import torch.nn as nn

# 1D BatchNorm (é€‚ç”¨äºå…¨è¿æ¥å±‚)
bn1d = nn.BatchNorm1d(num_features=64)  # è¾“å…¥ç‰¹å¾ç»´åº¦ä¸º 64

# è¾“å…¥æ•°æ® (batch_size=32, num_features=64)
x = torch.randn(32, 64)
out = bn1d(x)  # è¾“å‡º shape: (32, 64)

# è¾“å…¥æ•°æ® (batch_size=32, num_features=64, sequence_length=100)
x = torch.randn(32, 64, 100)
out = bn1d(x)  # è¾“å‡º shape: (32, 64, 100)
```

***

## **2. `nn.BatchNorm2d`ï¼ˆ2D æ‰¹é‡è§„èŒƒåŒ–ï¼‰**

### **é€‚ç”¨åœºæ™¯**

*   **å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰** çš„ç‰¹å¾å›¾ï¼ˆæœ€å¸¸ç”¨ï¼‰ã€‚
*   **2D å›¾åƒæ•°æ®**ï¼ˆå¦‚ `(B, C, H, W)`ï¼‰ã€‚

### **è¾“å…¥æ•°æ®æ ¼å¼**

*   **Shape**: `(batch_size, num_channels, height, width)`ã€‚
*   **å½’ä¸€åŒ–ç»´åº¦**ï¼šå¯¹ `num_channels` çš„æ¯ä¸ªé€šé“å•ç‹¬è®¡ç®—å‡å€¼å’Œæ–¹å·®ï¼ˆå³æ¯ä¸ªé€šé“ç‹¬ç«‹å½’ä¸€åŒ–ï¼‰ã€‚

### **ç¤ºä¾‹**

```python
# 2D BatchNorm (é€‚ç”¨äº CNN)
bn2d = nn.BatchNorm2d(num_features=64)  # è¾“å…¥é€šé“æ•°ä¸º 64

# è¾“å…¥æ•°æ® (batch_size=32, channels=64, height=28, width=28)
x = torch.randn(32, 64, 28, 28)
out = bn2d(x)  # è¾“å‡º shape: (32, 64, 28, 28)
```

***

## **3. `nn.BatchNorm3d`ï¼ˆ3D æ‰¹é‡è§„èŒƒåŒ–ï¼‰**

### **é€‚ç”¨åœºæ™¯**

*   **3D æ•°æ®**ï¼ˆå¦‚è§†é¢‘ã€3D åŒ»å­¦å›¾åƒï¼‰ã€‚
*   **3D å·ç§¯ï¼ˆConv3Dï¼‰** çš„ç‰¹å¾å›¾ã€‚

### **è¾“å…¥æ•°æ®æ ¼å¼**

*   **Shape**: `(batch_size, num_channels, depth, height, width)`ã€‚
*   **å½’ä¸€åŒ–ç»´åº¦**ï¼šå¯¹ `num_channels` çš„æ¯ä¸ªé€šé“å•ç‹¬è®¡ç®—å‡å€¼å’Œæ–¹å·®ã€‚

### **ç¤ºä¾‹**

```python
# 3D BatchNorm (é€‚ç”¨äº 3D æ•°æ®)
bn3d = nn.BatchNorm3d(num_features=64)  # è¾“å…¥é€šé“æ•°ä¸º 64

# è¾“å…¥æ•°æ® (batch_size=32, channels=64, depth=16, height=28, width=28)
x = torch.randn(32, 64, 16, 28, 28)
out = bn3d(x)  # è¾“å‡º shape: (32, 64, 16, 28, 28)
```

***

## **4. ä¼ å‚åŒºåˆ«**

æ‰€æœ‰ `BatchNorm` å±‚çš„å‚æ•°åŸºæœ¬ç›¸åŒï¼Œä½† **`num_features` çš„å«ä¹‰ä¸åŒ**ï¼š

| å‚æ•°                    | è¯´æ˜                                                                                                            |
| --------------------- | ------------------------------------------------------------------------------------------------------------- |
| `num_features`        | è¾“å…¥æ•°æ®çš„ **ç‰¹å¾ç»´åº¦**ï¼ˆ`BatchNorm1d` æ˜¯ `num_features`ï¼Œ`BatchNorm2d` æ˜¯ `num_channels`ï¼Œ`BatchNorm3d` æ˜¯ `num_channels`ï¼‰ã€‚ |
| `eps`                 | é˜²æ­¢é™¤é›¶çš„å°å¸¸æ•°ï¼ˆé»˜è®¤ `1e-5`ï¼‰ã€‚                                                                                          |
| `momentum`            | ç”¨äºè®¡ç®—å…¨å±€ç»Ÿè®¡é‡çš„åŠ¨é‡ï¼ˆé»˜è®¤ `0.1`ï¼‰ã€‚                                                                                       |
| `affine`              | æ˜¯å¦å­¦ä¹  `gamma` å’Œ `beta`ï¼ˆé»˜è®¤ `True`ï¼‰ã€‚                                                                             |
| `track_running_stats` | æ˜¯å¦è®°å½•å…¨å±€å‡å€¼å’Œæ–¹å·®ï¼ˆé»˜è®¤ `True`ï¼‰ã€‚                                                                                       |

### **ç¤ºä¾‹ï¼ˆä¼ å‚å¯¹æ¯”ï¼‰**

```python
# BatchNorm1d
bn1d = nn.BatchNorm1d(num_features=64, eps=1e-5, momentum=0.1, affine=True, track_running_stats=True)

# BatchNorm2d
bn2d = nn.BatchNorm2d(num_features=64, eps=1e-5, momentum=0.1, affine=True, track_running_stats=True)

# BatchNorm3d
bn3d = nn.BatchNorm3d(num_features=64, eps=1e-5, momentum=0.1, affine=True, track_running_stats=True)
```

***

## **5. æ€»ç»“**

| å‡½æ•°            | é€‚ç”¨æ•°æ®              | è¾“å…¥ Shape               | å½’ä¸€åŒ–ç»´åº¦   |
| ------------- | ----------------- | ---------------------- | ------- |
| `BatchNorm1d` | 1D æ•°æ®ï¼ˆFCã€æ—¶åºï¼‰      | `(B, F)` æˆ– `(B, F, L)` | `F`ï¼ˆç‰¹å¾ï¼‰ |
| `BatchNorm2d` | 2D æ•°æ®ï¼ˆCNN å›¾åƒï¼‰     | `(B, C, H, W)`         | `C`ï¼ˆé€šé“ï¼‰ |
| `BatchNorm3d` | 3D æ•°æ®ï¼ˆè§†é¢‘ã€3D åŒ»å­¦å›¾åƒï¼‰ | `(B, C, D, H, W)`      | `C`ï¼ˆé€šé“ï¼‰ |

**å…³é”®ç‚¹**ï¼š

1.  **`BatchNorm1d`** é€‚ç”¨äºå…¨è¿æ¥å±‚æˆ–æ—¶åºæ•°æ®ã€‚
2.  **`BatchNorm2d`** é€‚ç”¨äº CNN å›¾åƒæ•°æ®ï¼ˆæœ€å¸¸ç”¨ï¼‰ã€‚
3.  **`BatchNorm3d`** é€‚ç”¨äº 3D æ•°æ®ï¼ˆå¦‚è§†é¢‘ï¼‰ã€‚
4.  **`num_features` çš„å«ä¹‰ä¸åŒ**ï¼š
    *   `BatchNorm1d`ï¼šç‰¹å¾æ•°ï¼ˆ`F`ï¼‰ã€‚
    *   `BatchNorm2d/3d`ï¼šé€šé“æ•°ï¼ˆ`C`ï¼‰ã€‚
5.  **å…¶ä»–å‚æ•°ï¼ˆ`eps`, `momentum`, `affine`ï¼‰åœ¨æ‰€æœ‰ BN å±‚ä¸­ä½œç”¨ç›¸åŒ**ã€‚

å¸Œæœ›è¿™ä¸ªè§£é‡Šèƒ½å¸®åŠ©ä½ æ¸…æ™°ç†è§£ PyTorch ä¸­ `BatchNorm` ç³»åˆ—çš„åŒºåˆ«ï¼ ğŸš€

### **é¢„æµ‹ï¼ˆæ¨ç†ï¼‰è¿‡ç¨‹ä¸­çš„æ‰¹é‡è§„èŒƒåŒ– vs. è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ‰¹é‡è§„èŒƒåŒ–**

åœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œæ‰¹é‡è§„èŒƒåŒ–ï¼ˆBatch Normalization, BNï¼‰åœ¨ **è®­ç»ƒï¼ˆTrainingï¼‰** å’Œ **é¢„æµ‹ï¼ˆInference/Testingï¼‰** é˜¶æ®µçš„è®¡ç®—æ–¹å¼æœ‰æ˜¾è‘—åŒºåˆ«ï¼Œä¸»è¦æ¶‰åŠ **å‡å€¼å’Œæ–¹å·®çš„è®¡ç®—æ¥æº**ã€‚ä»¥ä¸‹æ˜¯è¯¦ç»†å¯¹æ¯”ï¼š

***

## **1. è®­ç»ƒé˜¶æ®µï¼ˆTrainingï¼‰**

### **è®¡ç®—æ–¹å¼**

åœ¨è®­ç»ƒæ—¶ï¼ŒBN çš„å‡å€¼å’Œæ–¹å·®æ˜¯ **åŸºäºå½“å‰ mini-batch çš„æ•°æ®åŠ¨æ€è®¡ç®—** çš„ï¼š

*   **å‡å€¼**ï¼š

```math
    \mu\_{\text{batch}} = \frac{1}{m} \sum\_{i=1}^m x\_i \quad (m = \text{batch\_size})
```

*   **æ–¹å·®**ï¼š

```math
    \sigma^2\_{\text{batch}} = \frac{1}{m} \sum\_{i=1}^m (x\_i - \mu\_{\text{batch}})^2
```

*   **æ ‡å‡†åŒ–**ï¼š

```math
    \hat{x}*i = \frac{x\_i - \mu*{\text{batch}}}{\sqrt{\sigma^2\_{\text{batch}} + \epsilon}}
```

*   **ç¼©æ”¾å’Œå¹³ç§»**ï¼š

```math
    y\_i = \gamma \hat{x}\_i + \beta \quad (\gamma, \beta \text{ æ˜¯å¯å­¦ä¹ å‚æ•°})
```

### **å…¨å±€ç»Ÿè®¡é‡çš„æ›´æ–°**

è®­ç»ƒæ—¶ï¼ŒBN ä¼š **ç´¯ç§¯ç§»åŠ¨å¹³å‡å€¼**ï¼ˆExponential Moving Average, EMAï¼‰ï¼Œç”¨äºé¢„æµ‹é˜¶æ®µï¼š

*   **å…¨å±€å‡å€¼**ï¼š

```math
    \mu\_{\text{global}} \leftarrow \alpha \mu\_{\text{global}} + (1 - \alpha) \mu\_{\text{batch}}
```

*   **å…¨å±€æ–¹å·®**ï¼š

```math
    \sigma^2\_{\text{global}} \leftarrow \alpha \sigma^2\_{\text{global}} + (1 - \alpha) \sigma^2\_{\text{batch}}
```

å…¶ä¸­ `$( \alpha )$` æ˜¯åŠ¨é‡å‚æ•°ï¼ˆé€šå¸¸è®¾ä¸º 0.9 æˆ– 0.99ï¼‰ã€‚

### **ç‰¹ç‚¹**

*   **ä¾èµ–å½“å‰ batch**ï¼šå‡å€¼å’Œæ–¹å·®æ˜¯åŠ¨æ€è®¡ç®—çš„ã€‚
*   **éšæœºæ€§**ï¼šä¸åŒ batch çš„ç»Ÿè®¡é‡å¯èƒ½ä¸åŒï¼ˆå—æ•°æ®åˆ†å¸ƒå½±å“ï¼‰ã€‚
*   **æ¢¯åº¦å›ä¼ **ï¼šå‚ä¸åå‘ä¼ æ’­ï¼Œä¼˜åŒ– `$( \gamma )$` å’Œ `$( \beta )$`ã€‚

***

## **2. é¢„æµ‹é˜¶æ®µï¼ˆInferenceï¼‰**

### **è®¡ç®—æ–¹å¼**

åœ¨é¢„æµ‹æ—¶ï¼ŒBN çš„å‡å€¼å’Œæ–¹å·® **ä¸å†ä¾èµ–å½“å‰è¾“å…¥æ•°æ®**ï¼Œè€Œæ˜¯ç›´æ¥ä½¿ç”¨è®­ç»ƒé˜¶æ®µç´¯ç§¯çš„ **å…¨å±€ç»Ÿè®¡é‡**ï¼ˆEMAï¼‰ï¼š

*   **æ ‡å‡†åŒ–**ï¼š

```math
    \hat{x}*i = \frac{x\_i - \mu*{\text{global}}}{\sqrt{\sigma^2\_{\text{global}} + \epsilon}}
```

*   **ç¼©æ”¾å’Œå¹³ç§»**ï¼š

```math
    y\_i = \gamma \hat{x}\_i + \beta
```

### **å…³é”®åŒºåˆ«**

1.  **å›ºå®šç»Ÿè®¡é‡**ï¼š
    *   ä½¿ç”¨è®­ç»ƒæ—¶è®¡ç®—çš„  `$( \mu_{\text{global}} ) $`å’Œ `$( \sigma^2_{\text{global}} )$`ï¼Œè€Œéå½“å‰ batch çš„ç»Ÿè®¡é‡ã€‚
2.  **ç¡®å®šæ€§è¾“å‡º**ï¼š
    *   ç›¸åŒè¾“å…¥å§‹ç»ˆå¾—åˆ°ç›¸åŒè¾“å‡ºï¼ˆæ—  batch é—´æ³¢åŠ¨ï¼‰ã€‚
3.  **æ— æ¢¯åº¦è®¡ç®—**ï¼š
    *   ä¸æ›´æ–° `$( \gamma )ã€( \beta )ã€( \mu_{\text{global}} )ã€( \sigma^2_{\text{global}} )$`ã€‚

### **ä¸ºä»€ä¹ˆè¿™æ ·åšï¼Ÿ**

*   **ä¸€è‡´æ€§**ï¼šé¢„æµ‹æ—¶å¯èƒ½åªæœ‰ä¸€ä¸ªæ ·æœ¬ï¼ˆbatch\_size=1ï¼‰ï¼Œæ— æ³•è®¡ç®— batch ç»Ÿè®¡é‡ã€‚
*   **ç¨³å®šæ€§**ï¼šé¿å…å›  batch æ•°æ®åˆ†å¸ƒä¸åŒå¯¼è‡´çš„è¾“å‡ºæ³¢åŠ¨ã€‚

***

## **3. ä»£ç å®ç°å¯¹æ¯”**

### **è®­ç»ƒé˜¶æ®µï¼ˆPyTorch ç¤ºä¾‹ï¼‰**

```python
import torch.nn as nn

bn = nn.BatchNorm2d(num_features=64)  # åˆå§‹åŒ– BN å±‚
x = torch.randn(32, 64, 28, 28)     # è¾“å…¥æ•°æ® (batch_size=32)

# è®­ç»ƒæ¨¡å¼ï¼ˆé»˜è®¤ï¼‰
bn.train()
output = bn(x)  # ä½¿ç”¨å½“å‰ batch çš„å‡å€¼å’Œæ–¹å·®ï¼Œå¹¶æ›´æ–°å…¨å±€ç»Ÿè®¡é‡
```

### **é¢„æµ‹é˜¶æ®µï¼ˆPyTorch ç¤ºä¾‹ï¼‰**

```python
bn.eval()       # åˆ‡æ¢åˆ°é¢„æµ‹æ¨¡å¼
with torch.no_grad():
    output = bn(x)  # ä½¿ç”¨å…¨å±€ç»Ÿè®¡é‡ Î¼_global å’Œ ÏƒÂ²_global
```

***

## **4. ç‰¹æ®Šæƒ…å†µå¤„ç†**

### **(1) Batch Size ä¸º 1 çš„é¢„æµ‹**

*   è®­ç»ƒæ—¶ï¼šå¦‚æœ `batch_size=1`ï¼Œæ–¹å·®è®¡ç®—ä¼šä¸º 0ï¼ˆå› ä¸ºå•ä¸€æ ·æœ¬æ— æ–¹å·®ï¼‰ï¼Œå¯¼è‡´æ•°å€¼ä¸ç¨³å®šã€‚
*   é¢„æµ‹æ—¶ï¼šç›´æ¥ä½¿ç”¨å…¨å±€ç»Ÿè®¡é‡ï¼Œé¿å…æ­¤é—®é¢˜ã€‚

### **(2) æ¨¡å‹åŠ è½½æ—¶çš„ç»Ÿè®¡é‡**

*   è®­ç»ƒå®Œæˆåï¼Œéœ€ä¿å­˜æ¨¡å‹çš„å…¨å±€ç»Ÿè®¡é‡ï¼ˆ`running_mean` å’Œ `running_var`ï¼‰ï¼Œå¦åˆ™é¢„æµ‹æ—¶å¯èƒ½å‡ºé”™ã€‚

***

## **5. æ€»ç»“å¯¹æ¯”**

| ç‰¹æ€§         | è®­ç»ƒé˜¶æ®µï¼ˆTrainingï¼‰                                        | é¢„æµ‹é˜¶æ®µï¼ˆInferenceï¼‰                                         |
| ---------- | ----------------------------------------------------- | ------------------------------------------------------- |
| **ç»Ÿè®¡é‡æ¥æº**  | å½“å‰ mini-batch è®¡ç®—                                      | è®­ç»ƒæ—¶ç´¯ç§¯çš„å…¨å±€ç»Ÿè®¡é‡ï¼ˆEMAï¼‰                                        |
| **è®¡ç®—æ–¹å¼**   | ( `$\mu\_{\text{batch}}, \sigma^2\_{\text{batch}}$` ) | (`$ \mu\_{\text{global}}, \sigma^2\_{\text{global}} $`) |
| **æ˜¯å¦æ›´æ–°å‚æ•°** | æ›´æ–° ( `$\gamma, \beta$` )ï¼Œå¹¶ç´¯ç§¯ EMA                      | å›ºå®šæ‰€æœ‰å‚æ•°                                                  |
| **è¾“å…¥ä¾èµ–**   | ä¾èµ–å½“å‰ batch æ•°æ®                                         | ä¸ä¾èµ–è¾“å…¥æ•°æ®                                                 |
| **è¾“å‡ºç¡®å®šæ€§**  | éšæœºï¼ˆå— batch å½±å“ï¼‰                                        | ç¡®å®šï¼ˆç›¸åŒè¾“å…¥ â†’ ç›¸åŒè¾“å‡ºï¼‰                                         |
| **é€‚ç”¨åœºæ™¯**   | `model.train()`                                       | `model.eval()`                                          |

***

## **6. æ•°å­¦å…¬å¼æ€»ç»“**

### **è®­ç»ƒé˜¶æ®µ**

```math
\hat{x}*i = \frac{x\_i - \mu*{\text{batch}}}{\sqrt{\sigma^2\_{\text{batch}} + \epsilon}}, \quad y\_i = \gamma \hat{x}\_i + \beta
```

### **é¢„æµ‹é˜¶æ®µ**

```math
\hat{x}*i = \frac{x\_i - \mu*{\text{global}}}{\sqrt{\sigma^2\_{\text{global}} + \epsilon}}, \quad y\_i = \gamma \hat{x}\_i + \beta
```

***

é€šè¿‡è¿™ç§è®¾è®¡ï¼ŒBN åœ¨è®­ç»ƒæ—¶ä¿æŒçµæ´»æ€§ï¼Œåœ¨é¢„æµ‹æ—¶ä¿è¯ç¨³å®šæ€§ï¼Œæ˜¯æ·±åº¦å­¦ä¹ æ¨¡å‹ä¼˜åŒ–çš„å…³é”®æŠ€æœ¯ä¹‹ä¸€ï¼

## BatchNorm2d è¿™ä¸ªå‡½æ˜¯æ€ä¹ˆæ›´æ–°å…¨å±€å‡å€¼å’Œæ–¹å·®çš„

åœ¨ PyTorch ä¸­ï¼Œ`nn.BatchNorm2d` é€šè¿‡ **æŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼ˆExponential Moving Average, EMAï¼‰** æ›´æ–°å…¨å±€å‡å€¼å’Œæ–¹å·®ï¼Œå…·ä½“è¿‡ç¨‹å¦‚ä¸‹ï¼š

***

### **1. å…¨å±€ç»Ÿè®¡é‡çš„å®šä¹‰**

*   **`running_mean`**ï¼šå…¨å±€å‡å€¼ `$( \mu_{\text{global}} )$`
*   **`running_var`**ï¼šå…¨å±€æ–¹å·® `$( \sigma^2_{\text{global}} )$`
*   **`momentum`**ï¼šåŠ¨é‡å‚æ•° `$( \alpha )$`ï¼ˆé»˜è®¤ 0.1ï¼‰ï¼Œæ§åˆ¶æ–°æ—§ç»Ÿè®¡é‡çš„æƒé‡ã€‚

***

### **2. æ›´æ–°å…¬å¼**

åœ¨æ¯æ¬¡å‰å‘ä¼ æ’­ï¼ˆè®­ç»ƒæ—¶ï¼‰ä¸­ï¼Œæ ¹æ®å½“å‰ batch çš„ç»Ÿè®¡é‡æ›´æ–°å…¨å±€ç»Ÿè®¡é‡ï¼š

```math
\mu\_{\text{global}} \leftarrow (1 - \alpha) \cdot \mu\_{\text{global}} + \alpha \cdot \mu\_{\text{batch}}
```

```math
\sigma^2\_{\text{global}} \leftarrow (1 - \alpha) \cdot \sigma^2\_{\text{global}} + \alpha \cdot \sigma^2\_{\text{batch}}
```

#### **å‚æ•°è¯´æ˜**ï¼š

*   ( `$\mu\_{\text{batch}}$` )ï¼šå½“å‰ batch çš„å‡å€¼ã€‚
*   ( `$\sigma^2\_{\text{batch}}$` )ï¼šå½“å‰ batch çš„æ–¹å·®ï¼ˆæ— åä¼°è®¡ï¼Œåˆ†æ¯ä¸º ( m )ï¼‰ã€‚
*   ( `$\alpha$` )ï¼šåŠ¨é‡å‚æ•°ï¼ˆ`momentum`ï¼‰ï¼Œå†³å®šæ–°ç»Ÿè®¡é‡çš„æ›´æ–°å¹…åº¦ã€‚

***

### **3. PyTorch çš„å…·ä½“å®ç°**

#### **ï¼ˆ1ï¼‰åˆå§‹åŒ–ç»Ÿè®¡é‡**

åˆ›å»º `BatchNorm2d` æ—¶ï¼Œå…¨å±€ç»Ÿè®¡é‡åˆå§‹åŒ–ä¸ºï¼š

*   `running_mean = 0`
*   `running_var = 1`\
    ï¼ˆè‹¥è¾“å…¥æ•°æ®å·²æ ‡å‡†åŒ–ï¼Œåˆå§‹æ–¹å·®ä¸º 1 å¯é¿å…åˆå§‹é˜¶æ®µæ•°å€¼ä¸ç¨³å®šï¼‰

#### **ï¼ˆ2ï¼‰è®­ç»ƒæ¨¡å¼ä¸‹çš„æ›´æ–°**

åœ¨ `forward()` ä¸­ï¼Œè‹¥ `self.training=True`ï¼Œåˆ™æ›´æ–°å…¨å±€ç»Ÿè®¡é‡ï¼š

```python
def forward(self, input):
    if self.training:
        # è®¡ç®—å½“å‰ batch çš„å‡å€¼å’Œæ–¹å·®
        mean = input.mean(dim=(0, 2, 3), keepdim=True)  # shape: [1, C, 1, 1]
        var = input.var(dim=(0, 2, 3), unbiased=False, keepdim=True)
        
        # æ›´æ–°å…¨å±€ç»Ÿè®¡é‡ï¼ˆEMAï¼‰
        self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * mean.squeeze()
        self.running_var = (1 - self.momentum) * self.running_var + self.momentum * var.squeeze()
    else:
        # é¢„æµ‹é˜¶æ®µç›´æ¥ä½¿ç”¨ running_mean å’Œ running_var
        mean = self.running_mean
        var = self.running_var
    
    # æ ‡å‡†åŒ–å’Œä»¿å°„å˜æ¢
    output = (input - mean) / torch.sqrt(var + self.eps)
    if self.affine:
        output = output * self.weight + self.bias
    return output
```

#### **å…³é”®ç‚¹**ï¼š

*   **æ— åæ–¹å·®**ï¼šPyTorch é»˜è®¤ä½¿ç”¨æ— åæ–¹å·®ï¼ˆ`unbiased=True`ï¼‰è®¡ç®— `ÏƒÂ²_batch`ï¼Œä½†æ›´æ–° `running_var` æ—¶ä½¿ç”¨æœ‰åä¼°è®¡ï¼ˆ`unbiased=False`ï¼‰ã€‚
*   **ç»´åº¦å¤„ç†**ï¼š`mean` å’Œ `var` è®¡ç®—æ—¶å‹ç¼©äº† `(0, 2, 3)` ç»´åº¦ï¼Œå¾—åˆ° `[C]` çš„å½¢çŠ¶ã€‚

***

### **4. åŠ¨é‡å‚æ•°ï¼ˆ`momentum`ï¼‰çš„ä½œç”¨**

*   **`momentum=0.1`**ï¼ˆé»˜è®¤å€¼ï¼‰ï¼š\
    æ–° batch çš„ç»Ÿè®¡é‡å  10%ï¼Œå†å²ç»Ÿè®¡é‡å  90%ï¼Œæ›´æ–°è¾ƒå¹³ç¼“ã€‚\
    å…¬å¼ï¼š

```math
    \mu\_{\text{global}} \leftarrow 0.9 \cdot \mu\_{\text{global}} + 0.1 \cdot \mu\_{\text{batch}}
```

*   **`momentum=0.01`**ï¼ˆå° batch æ—¶æ¨èï¼‰ï¼š\
    æ›´æ–°æ›´ç¼“æ…¢ï¼Œå‡å°‘å™ªå£°å½±å“ã€‚

***

### **5. éªŒè¯ä»£ç ç¤ºä¾‹**

```python
import torch
import torch.nn as nn

# åˆå§‹åŒ– BN å±‚ï¼ˆé€šé“æ•°=3ï¼‰
bn = nn.BatchNorm2d(3, momentum=0.1)
print("åˆå§‹ running_mean:", bn.running_mean)  # tensor([0., 0., 0.])
print("åˆå§‹ running_var:", bn.running_var)    # tensor([1., 1., 1.])

# æ¨¡æ‹Ÿè¾“å…¥æ•°æ® (batch=2, channels=3, height=2, width=2)
x = torch.randn(2, 3, 2, 2)

# è®­ç»ƒæ¨¡å¼ï¼ˆæ›´æ–°å…¨å±€ç»Ÿè®¡é‡ï¼‰
bn.train()
output = bn(x)
print("ç¬¬ä¸€æ¬¡æ›´æ–°åçš„ running_mean:", bn.running_mean)
print("ç¬¬ä¸€æ¬¡æ›´æ–°åçš„ running_var:", bn.running_var)

# ç¬¬äºŒæ¬¡å‰å‘ä¼ æ’­
output = bn(x)
print("ç¬¬äºŒæ¬¡æ›´æ–°åçš„ running_mean:", bn.running_mean)
```

#### **è¾“å‡ºç»“æœ**ï¼š

    åˆå§‹ running_mean: tensor([0., 0., 0.])
    åˆå§‹ running_var: tensor([1., 1., 1.])

    ç¬¬ä¸€æ¬¡æ›´æ–°åçš„ running_mean: tensor([-0.0102,  0.1234, -0.0567])  # â‰ˆ 0.1 * Î¼_batch
    ç¬¬ä¸€æ¬¡æ›´æ–°åçš„ running_var: tensor([0.9901, 1.0345, 0.9789])     # â‰ˆ 0.1 * ÏƒÂ²_batch + 0.9 * 1

    ç¬¬äºŒæ¬¡æ›´æ–°åçš„ running_mean: tensor([-0.0201,  0.2345, -0.1102])  # ç»§ç»­ç´¯ç§¯

***

### **6. æ³¨æ„äº‹é¡¹**

1.  **`eval()` æ¨¡å¼å†»ç»“ç»Ÿè®¡é‡**ï¼š\
    è°ƒç”¨ `bn.eval()` åï¼Œ`running_mean` å’Œ `running_var` ä¸å†æ›´æ–°ã€‚
2.  **æ‰‹åŠ¨åŠ è½½ç»Ÿè®¡é‡**ï¼š\
    è‹¥ä»æ£€æŸ¥ç‚¹åŠ è½½æ¨¡å‹ï¼Œéœ€ç¡®ä¿ `running_mean` å’Œ `running_var` ä¹Ÿè¢«æ­£ç¡®åŠ è½½ã€‚
3.  **Batch Size å½±å“**ï¼š\
    å° batch å¯èƒ½å¯¼è‡´ `ÏƒÂ²_batch` ä¼°è®¡ä¸å‡†ï¼Œå»ºè®® `batch_size â‰¥ 16`ã€‚

***

### **æ€»ç»“**

PyTorch çš„ `nn.BatchNorm2d` é€šè¿‡ **æŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼ˆEMAï¼‰** æ›´æ–°å…¨å±€å‡å€¼å’Œæ–¹å·®ï¼š

1.  **è®­ç»ƒé˜¶æ®µ**ï¼š
    *   è®¡ç®—å½“å‰ batch çš„ `$( \mu_{\text{batch}} )$` å’Œ `$( \sigma^2_{\text{batch}} )$`ã€‚
    *   æŒ‰ `momentum` æƒé‡æ›´æ–° `running_mean` å’Œ `running_var`ã€‚
2.  **é¢„æµ‹é˜¶æ®µ**ï¼š
    *   å›ºå®šä½¿ç”¨è®­ç»ƒç´¯ç§¯çš„ `running_mean` å’Œ `running_var`ã€‚

è¿™ç§è®¾è®¡ç¡®ä¿äº†è®­ç»ƒæ—¶çµæ´»é€‚åº”æ•°æ®åˆ†å¸ƒï¼Œé¢„æµ‹æ—¶ç¨³å®šè¾“å‡ºã€‚

å¥½çš„ï¼æˆ‘å°†é€šè¿‡**å…·ä½“æ•°æ®**å’Œ**åˆ†æ­¥è®¡ç®—**ï¼Œè¯¦ç»†è§£é‡Š `nn.BatchNorm2d` çš„è®¡ç®—è¿‡ç¨‹ï¼Œå¸®åŠ©ä½ å½»åº•ç†è§£å…¶åŸç†ã€‚

***

### **1. BatchNorm2d çš„æ ¸å¿ƒæ€æƒ³**

*   **ä½œç”¨**ï¼šå¯¹4Dè¾“å…¥å¼ é‡ï¼ˆå›¾åƒæ•°æ®ï¼‰çš„æ¯ä¸ªé€šé“ï¼ˆChannelï¼‰è¿›è¡Œå½’ä¸€åŒ–ï¼Œç¨³å®šè®­ç»ƒè¿‡ç¨‹ã€‚
*   **è¾“å…¥å½¢çŠ¶**ï¼š`(batch_size, num_channels, height, width)`\
    ï¼ˆå¦‚ä¸€æ‰¹RGBå›¾åƒï¼š`(B, 3, H, W)`ï¼‰
*   **å½’ä¸€åŒ–ç»´åº¦**ï¼šåœ¨ `Batch` ç»´åº¦ä¸Šè®¡ç®—å‡å€¼å’Œæ–¹å·®ï¼ˆå³å¯¹æ¯ä¸ªé€šé“çš„æ‰€æœ‰åƒç´ å•ç‹¬å½’ä¸€åŒ–ï¼‰ã€‚

***

### **2. å…·ä½“æ•°æ®ç¤ºä¾‹**

å‡è®¾è¾“å…¥å¼ é‡ `x` è¡¨ç¤º **2å¼ 2x2çš„RGBå›¾åƒ**ï¼ˆæ¨¡æ‹Ÿå°æ‰¹é‡æ•°æ®ï¼‰ï¼š

```python
import torch

x = torch.tensor([
    # å›¾åƒ1 (2ä¸ªé€šé“ï¼Œ2x2)
    [
        [[1.0, 2.0], [3.0, 4.0]],  # é€šé“1
        [[5.0, 6.0], [7.0, 8.0]]   # é€šé“2
    ],
    # å›¾åƒ2
    [
        [[9.0, 10.0], [11.0, 12.0]],  # é€šé“1
        [[13.0, 14.0], [15.0, 16.0]]  # é€šé“2
    ]
], dtype=torch.float32)  # å½¢çŠ¶: [2, 2, 2, 2] (B=2, C=2, H=2, W=2)
```

## BatchNorm2dçš„è®¡ç®—è¿‡ç¨‹

***

### **1. BatchNorm2d çš„æ ¸å¿ƒæ€æƒ³**

*   **ä½œç”¨**ï¼šå¯¹4Dè¾“å…¥å¼ é‡ï¼ˆå›¾åƒæ•°æ®ï¼‰çš„æ¯ä¸ªé€šé“ï¼ˆChannelï¼‰è¿›è¡Œå½’ä¸€åŒ–ï¼Œç¨³å®šè®­ç»ƒè¿‡ç¨‹ã€‚
*   **è¾“å…¥å½¢çŠ¶**ï¼š`(batch_size, num_channels, height, width)`\
    ï¼ˆå¦‚ä¸€æ‰¹RGBå›¾åƒï¼š`(B, 3, H, W)`ï¼‰
*   **å½’ä¸€åŒ–ç»´åº¦**ï¼šåœ¨ `Batch` ç»´åº¦ä¸Šè®¡ç®—å‡å€¼å’Œæ–¹å·®ï¼ˆå³å¯¹æ¯ä¸ªé€šé“çš„æ‰€æœ‰åƒç´ å•ç‹¬å½’ä¸€åŒ–ï¼‰ã€‚

***

### **2. å…·ä½“æ•°æ®ç¤ºä¾‹**

å‡è®¾è¾“å…¥å¼ é‡ `x` è¡¨ç¤º **2å¼ 2x2çš„RGBå›¾åƒ**ï¼ˆæ¨¡æ‹Ÿå°æ‰¹é‡æ•°æ®ï¼‰ï¼š

```python
import torch

x = torch.tensor([
    # å›¾åƒ1 (2ä¸ªé€šé“ï¼Œ2x2)
    [
        [[1.0, 2.0], [3.0, 4.0]],  # é€šé“1
        [[5.0, 6.0], [7.0, 8.0]]   # é€šé“2
    ],
    # å›¾åƒ2
    [
        [[9.0, 10.0], [11.0, 12.0]],  # é€šé“1
        [[13.0, 14.0], [15.0, 16.0]]  # é€šé“2
    ]
], dtype=torch.float32)  # å½¢çŠ¶: [2, 2, 2, 2] (B=2, C=2, H=2, W=2)
```

### **3. è®¡ç®—è¿‡ç¨‹è¯¦è§£**

#### **(1) è®¡ç®—é€šé“å‡å€¼å’Œæ–¹å·®**

å¯¹**æ¯ä¸ªé€šé“**çš„æ‰€æœ‰åƒç´ ï¼ˆ**è·¨Batchå’Œç©ºé—´ç»´åº¦**ï¼‰è®¡ç®—å‡å€¼å’Œæ–¹å·®ï¼š

*   **é€šé“1**çš„åƒç´ ï¼š`1, 2, 3, 4, 9, 10, 11, 12`

```math
  \mu_1 = \frac{1+2+3+4+9+10+11+12}{8} = 6.5 \\
  \sigma_1^2 = \frac{(1-6.5)^2 + (2-6.5)^2 + \dots + (12-6.5)^2}{8} = 15.25
```

*   **é€šé“2**çš„åƒç´ ï¼š`5, 6, 7, 8, 13, 14, 15, 16`

```math
 \mu_2 = \frac{5+6+7+8+13+14+15+16}{8} = 10.5 \\
 \sigma_2^2 = \frac{(5-10.5)^2 + \dots + (16-10.5)^2}{8} = 15.25
```

#### **(2) å½’ä¸€åŒ–ï¼ˆNormalizeï¼‰**

å¯¹æ¯ä¸ªé€šé“çš„åƒç´ å€¼è¿›è¡Œæ ‡å‡†åŒ–ï¼š

```math
\hat{x} = \frac{x - \mu}{\sqrt{\sigma^2 + \epsilon}}
```

ï¼ˆ`epsilon` æ˜¯ä¸ºé˜²æ­¢é™¤é›¶çš„å°å¸¸æ•°ï¼Œå¦‚ `1e-5`ï¼‰

*   **é€šé“1çš„å½’ä¸€åŒ–ç¤ºä¾‹**ï¼š

```math
  \hat{x}_{1,1,1,1} = \frac{1 - 6.5}{\sqrt{15.25 + 1e-5}} \approx -1.419
```

*   **é€šé“2çš„å½’ä¸€åŒ–ç¤ºä¾‹**ï¼š

```math
 \hat{x}_{1,2,1,1} = \frac{5 - 10.5}{\sqrt{15.25 + 1e-5}} \approx -1.419
```

#### **(3) ç¼©æ”¾å’Œå¹³ç§»ï¼ˆAffine Transformï¼‰**

å¼•å…¥å¯å­¦ä¹ çš„å‚æ•° `gamma`ï¼ˆç¼©æ”¾ï¼‰å’Œ `beta`ï¼ˆå¹³ç§»ï¼‰ï¼š

```math
y = \gamma \cdot \hat{x} + \beta
```

*   å‡è®¾åˆå§‹åŒ– `gamma=1`ï¼Œ`beta=0`ï¼Œåˆ™è¾“å‡ºä¸å½’ä¸€åŒ–å€¼ç›¸åŒã€‚

***

### **4. PyTorch ä»£ç éªŒè¯**

```python
import torch.nn as nn

# å®šä¹‰BatchNorm2d (num_features=é€šé“æ•°)
bn = nn.BatchNorm2d(num_features=2, affine=True, track_running_stats=True)

# åˆå§‹åŒ–gammaå’Œbetaä¸º1å’Œ0ï¼ˆä¾¿äºéªŒè¯ï¼‰
bn.weight.data = torch.ones(2)  # gamma
bn.bias.data = torch.zeros(2)   # beta

# å‰å‘è®¡ç®—
output = bn(x)
print(output)
```

**è¾“å‡ºç»“æœ**ï¼š

    tensor([
        [[[-1.4191, -1.1521], [-0.8850, -0.6180]],  # é€šé“1
         [[-1.4191, -1.1521], [-0.8850, -0.6180]]   # é€šé“2
        ],
        [[[ 0.6180,  0.8850], [ 1.1521,  1.4191]],  # é€šé“1
         [[ 0.6180,  0.8850], [ 1.1521,  1.4191]]   # é€šé“2
    ]])

*   ä¸æ‰‹åŠ¨è®¡ç®—ç»“æœä¸€è‡´ï¼ˆå¿½ç•¥æµ®ç‚¹è¯¯å·®ï¼‰ã€‚

***

### **5. è®­ç»ƒä¸æ¨ç†çš„åŒºåˆ«**

*   **è®­ç»ƒé˜¶æ®µ**ï¼š
    *   è®¡ç®—å½“å‰Batchçš„å‡å€¼å’Œæ–¹å·®ã€‚
    *   æ›´æ–°å…¨å±€ç»Ÿè®¡é‡ï¼ˆ`running_mean` å’Œ `running_var`ï¼‰ï¼Œç”¨äºæ¨ç†ã€‚
*   **æ¨ç†é˜¶æ®µ**ï¼š
    *   ä½¿ç”¨è®­ç»ƒç´¯è®¡çš„ `running_mean` å’Œ `running_var`ï¼Œè€Œéå½“å‰Batchçš„ç»Ÿè®¡é‡ã€‚

**æŸ¥çœ‹å…¨å±€ç»Ÿè®¡é‡**ï¼š

```python
print(bn.running_mean)  # é€šé“å‡å€¼çš„æŒ‡æ•°ç§»åŠ¨å¹³å‡
print(bn.running_var)   # é€šé“æ–¹å·®çš„æŒ‡æ•°ç§»åŠ¨å¹³å‡
```

***

### **6. å…³é”®ç‚¹æ€»ç»“**

| æ­¥éª¤          | è®¡ç®—å…¬å¼                                                     | è¾“å…¥å½¢çŠ¶           | è¾“å‡ºå½¢çŠ¶           |
| ----------- | -------------------------------------------------------- | -------------- | -------------- |
| **è®¡ç®—å‡å€¼/æ–¹å·®** | `$(\mu_c = \frac{1}{BHW}\sum x_c)$`                      | `[B, C, H, W]` | `[C]`          |
| **å½’ä¸€åŒ–**     | `$ (\hat{x} = \frac{x-\mu}{\sqrt{\sigma^2+\epsilon}}) $` | `[B, C, H, W]` | `[B, C, H, W]` |
| **ç¼©æ”¾å¹³ç§»**    | `$(y = \gamma \hat{x} + \beta) $`                        | `[B, C, H, W]` | `[B, C, H, W]` |

***

### **7. ä¸ºä»€ä¹ˆBatchNormæœ‰æ•ˆï¼Ÿ**

1.  **ç¨³å®šåˆ†å¸ƒ**ï¼šå‡å°‘å†…éƒ¨åå˜é‡åç§»ï¼ˆInternal Covariate Shiftï¼‰ã€‚
2.  **åŠ é€Ÿæ”¶æ•›**ï¼šå…è®¸æ›´å¤§çš„å­¦ä¹ ç‡ã€‚
3.  **æ­£åˆ™åŒ–æ•ˆæœ**ï¼šä¾èµ–Batchç»Ÿè®¡é‡å¸¦æ¥è½»å¾®å™ªå£°ï¼Œç±»ä¼¼Dropoutã€‚

***

### **8. å¸¸è§é—®é¢˜**

#### **Q1ï¼šBatch Sizeè¾ƒå°æ—¶ä¸ºä½•æ•ˆæœå·®ï¼Ÿ**

*   å°Batchçš„ç»Ÿè®¡é‡ä¼°è®¡ä¸å‡†ç¡®ï¼Œå¯¼è‡´å™ªå£°è¿‡å¤§ã€‚å¯å°è¯• `GroupNorm` æˆ– `LayerNorm`ã€‚

#### **Q2ï¼š`affine=False` çš„ä½œç”¨ï¼Ÿ**

*   ç¦ç”¨å¯å­¦ä¹ çš„ `gamma` å’Œ `beta`ï¼Œä»…åšå½’ä¸€åŒ–ã€‚

#### **Q3ï¼šå·ç§¯åä½•æ—¶ç”¨BatchNormï¼Ÿ**

*   é€šå¸¸åœ¨å·ç§¯å±‚åã€æ¿€æ´»å‡½æ•°å‰ä½¿ç”¨ï¼š
    ```python
    self.net = nn.Sequential(
        nn.Conv2d(3, 64, kernel_size=3),
        nn.BatchNorm2d(64),
        nn.ReLU()
    )
    ```

***

é€šè¿‡è¿™ä¸ªå…·ä½“ä¾‹å­ï¼Œä½ åº”è¯¥èƒ½æ¸…æ™°ç†è§£ `nn.BatchNorm2d` çš„è®¡ç®—é€»è¾‘äº†ï¼

## å’ŒLayerNormçš„å·®å¼‚

*   layerNormè®¡ç®—æ—¶æ˜¯ä¸è·¨æ—¶é—´æ­¥çš„
*   BatchNorm2Dæ˜¯è·¨Batchå’Œç©ºé—´ç»´åº¦ï¼Œä¸”è®¡ç®—çš„æ˜¯åé¢çš„æ‰€æœ‰ç»´åº¦
*   æ— è®ºæ˜¯ BatchNorm1dã€BatchNorm2d è¿˜æ˜¯ BatchNorm3dï¼Œæ‰€æœ‰BatchNormå˜ä½“å‡éœ€è¦è·¨Batchè®¡ç®—å‡å€¼å’Œæ–¹å·®ï¼Œè¿™æ˜¯BatchNormçš„æ ¸å¿ƒè®¾è®¡åŸåˆ™

