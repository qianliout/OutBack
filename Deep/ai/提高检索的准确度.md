在 RAG（Retrieval-Augmented Generation）系统中，优化检索环节是提升最终生成质量的关键。以下是提高检索准确度的系统性方法，涵盖算法、工程实践和高级策略：

***

## **1. 检索模型优化**

### **(1) 稠密检索 vs. 稀疏检索**

| **方法**   | **代表技术**               | **适用场景**      | **优化方向**                         |
| -------- | ---------------------- | ------------- | -------------------------------- |
| **稀疏检索** | BM25、TF-IDF            | 精确关键词匹配，冷启动阶段 | 扩展同义词、调整权重（如字段加权）                |
| **稠密检索** | DPR、ANCE、Sentence-BERT | 语义相似性搜索       | 微调嵌入模型、负采样策略优化                   |
| **混合检索** | BM25 + 向量检索            | 兼顾关键词和语义      | 动态权重融合（如 Reciprocal Rank Fusion） |

**代码示例（混合检索）**：

```python
from rank_bm25 import BM25Okapi
from sentence_transformers import SentenceTransformer

# 稀疏检索
bm25 = BM25Okapi(tokenized_docs)
sparse_scores = bm25.get_scores(query_tokens)

# 稠密检索
model = SentenceTransformer("paraphrase-multilingual-MiniLM-L12-v2")
query_embedding = model.encode(query)
dense_scores = np.dot(doc_embeddings, query_embedding)

# 加权融合
final_scores = 0.4 * sparse_scores + 0.6 * dense_scores
```

### **(2) 嵌入模型微调**

*   **领域适配**：在目标领域数据上微调 Sentence-BERT 或 DPR。
    ```python
    from sentence_transformers import InputExample, losses
    train_examples = [InputExample(texts=["query1", "pos_doc1"]), ...]
    train_dataloader = DataLoader(train_examples, batch_size=32)
    loss = losses.MultipleNegativesRankingLoss(model)
    model.fit(train_dataloader, epochs=3)
    ```
*   **对比学习**：使用难负例挖掘（Hard Negative Mining）提升区分度。

***

## **2. 文档预处理优化**

### **(1) 智能分块（Chunking）**

*   **动态分块**：根据内容类型调整分块大小（技术文档 vs. 对话记录）。
*   **语义分块**：用 TextTiling 或 BERTopic 检测主题边界。
*   **重叠策略**：设置 10-15% 的重叠避免信息割裂。

### **(2) 元数据增强**

*   **添加字段**：文档来源、章节标题、实体标签等。
*   **混合检索**：结合元数据过滤（如 `WHERE section='第三章'`）。

### **(3) 文本规范化**

*   **同义词扩展**：使用领域同义词库（如 `synonyms` 库）。
*   **拼写纠正**：集成 `pycorrector` 或 `symspellpy`。

***

## **3. 查询重写与扩展**

### **(1) 查询理解**

*   **实体识别**：用 NER 提取关键实体（如人名、术语）。
    ```python
    import jieba.analyse
    tags = jieba.analyse.extract_tags(query, withWeight=True)
    ```
*   **意图分类**：判断用户意图（搜索、问答、比较等）。

### **(2) 查询扩展**

*   **同义词扩展**：基于词向量或知识图谱。
    ```python
    from synonyms import nearby
    synonyms = nearby("苹果")[0][:3]  # 获取前3个同义词
    expanded_query = f"({' OR '.join(synonyms)})"
    ```
*   **生成式扩展**：用 LLM 生成相关查询。
    ```python
    prompt = f"生成与'{query}'相关的3个搜索查询:"
    related_queries = llm.generate(prompt)
    ```

***

## **4. 检索后处理（Re-Ranking）**

### **(1) 交叉编码器重排序**

*   **原理**：用计算量大的模型对 Top-K 结果精细排序。
    ```python
    from sentence_transformers import CrossEncoder
    cross_model = CrossEncoder("cross-encoder/ms-marco-MiniLM-L-6-v2")
    scores = cross_model.predict([(query, doc) for doc in top_100_docs])
    ```
*   **优势**：比双编码器更精准，适合小规模候选集。

### **(2) 多样性去重**

*   **MMR（Maximal Marginal Relevance）**：
    ```python
    from rank_bm25 import BM25Okapi
    from sklearn.metrics.pairwise import cosine_similarity

    def mmr(bm25_scores, doc_embeddings, lambda_param=0.7):
        selected = []
        while len(selected) < len(bm25_scores):
            remaining = [i for i in range(len(bm25_scores)) if i not in selected]
            mmr_scores = []
            for i in remaining:
                sim_to_selected = max([cosine_similarity([doc_embeddings[i]], [doc_embeddings[j]])[0][0] 
                                     for j in selected]) if selected else 0
                mmr_score = lambda_param * bm25_scores[i] - (1 - lambda_param) * sim_to_selected
                mmr_scores.append(mmr_score)
            next_idx = remaining[np.argmax(mmr_scores)]
            selected.append(next_idx)
        return selected
    ```

***

## **5. 系统级优化**

### **(1) 索引结构优化**

| **技术**    | **适用场景** | **工具示例**            |
| --------- | -------- | ------------------- |
| **分层索引**  | 十亿级文档    | FAISS-IVF, Milvus   |
| **标量量化**  | 内存受限场景   | FAISS-PQ            |
| **分布式索引** | 超大规模数据   | Elasticsearch+FAISS |

### **(2) 缓存策略**

*   **查询缓存**：缓存高频查询结果（Redis）。
*   **嵌入缓存**：预计算文档向量（节省 60%+ 计算时间）。

### **(3) 实时反馈**

*   **点击日志分析**：优化负采样（优先学习被跳过的文档）。
*   **人工标注**：持续校正排序模型。

***

## **6. 评估与迭代**

### **(1) 核心指标**

| **指标**            | **计算方法**       | **目标值**   |
| ----------------- | -------------- | --------- |
| **Recall\@K**     | 前K结果中相关文档占比    | K=5时 >80% |
| **MRR**           | 第一个相关结果的倒数排名均值 | >0.7      |
| **Query Latency** | 90%查询响应时间      | <200ms    |

### **(2) A/B测试框架**

```python
# 对比两种检索策略
def evaluate_strategy(query_set, strategy_a, strategy_b):
    a_hits = [strategy_a(q) in true_relevant_docs for q in query_set]
    b_hits = [strategy_b(q) in true_relevant_docs for q in query_set]
    return np.mean(a_hits), np.mean(b_hits)
```

***

## **总结：优化路径优先级**

1.  **基础优化**：分块策略 + BM25/向量混合检索 → 快速收益。
2.  **中级优化**：查询扩展 + 嵌入模型微调 → 准确度提升 15-30%。
3.  **高级优化**：重排序 + 动态分块 → 边际收益递减，需权衡计算成本。

通过组合上述方法，可显著提升 RAG 系统的检索准确度。建议从成本最低的查询重写和混合检索入手，逐步迭代到模型微调和系统架构优化。
