# 深度学习中的采样方法

## 采样方法概述

采样方法在深度学习中主要用于解决类别不平衡、计算效率和高维数据建模等问题。以下是几种常见采样方法的详细分析。

## 1. 负采样（Negative Sampling）

## 解决的问题

1.  处理词嵌入(word2vec)中的计算效率问题
2.  减少推荐系统中正负样本不平衡的影响
3.  降低softmax的计算复杂度

## 实现方式

```math
P(w_i|w_j) = \frac{\exp(v_{w_i}^T v_{w_j})}{\sum_{k=1}^K \exp(v_{w_k}^T v_{w_j})}
```

近似为：

```math
\log \sigma(v_{w_o}^T v_{w_j}) + \sum_{i=1}^k \mathbb{E}_{w_i \sim P_n(w)} [\log \sigma(-v_{w_i}^T v_{w_j})]
```

其中从噪声分布 `$P_n(w)$` 中采样k个负样本

## 优点

1.  将计算复杂度从 `$O(|V|)$` 降到 `$O(k)$` (k通常为5-20)
2.  特别适合大规模词汇表场景
3.  可以改善低频词的学习

## 缺点

1.  采样分布的选择影响模型性能
2.  可能引入采样偏差
3.  对高频词可能过度惩罚

## 典型应用

*   Word2Vec/Skip-gram模型
*   推荐系统中的隐式反馈处理
*   对比学习中的负样本构造

## 2. 下采样（Downsampling）

## 解决的问题

1.  类别不平衡问题（多数类样本远多于少数类）
2.  减少计算资源消耗
3.  缓解模型对多数类的偏见

## 实现方式

1.  随机丢弃多数类样本
2.  基于聚类的方法（保留聚类中心代表样本）
3.  Tomek links方法（移除边界附近的多数类样本）

## 优点

1.  平衡类别分布
2.  减少训练时间和内存消耗
3.  简单易实现

## 缺点

1.  可能丢失重要信息
2.  对小型数据集尤其不利
3.  可能降低模型性能如果丢弃了关键样本

## 典型应用

*   医学图像分析（如病灶检测）
*   欺诈检测
*   任何类别不平衡的分类任务

## 3. 上采样（Upsampling/Oversampling）

## 解决的问题

1.  类别不平衡问题（增加少数类样本）
2.  增强模型对少数类的学习能力

## 实现方式

1.  随机复制少数类样本（基本方法）
2.  SMOTE（Synthetic Minority Over-sampling Technique）：
    ```math
    x_{new} = x_i + \lambda \times (x_{zi} - x_i)
    ```
    其中 `$\lambda \in [0,1]$` 是随机数，`$x_{zi}$` 是x\_i的k近邻

## 优点

1.  不丢失原始信息
2.  SMOTE能生成有意义的合成样本
3.  改善模型对少数类的识别率

## 缺点

1.  随机复制可能导致过拟合
2.  SMOTE在高维空间效果下降
3.  可能加剧类别重叠问题

## 典型应用

*   罕见疾病诊断
*   异常检测
*   信用风险评估

## 4. 分层采样（Stratified Sampling）

## 解决的问题

1.  保持数据集的原始分布特性
2.  确保小类别在采样中得到代表

## 实现方式

1.  按类别比例划分训练/验证/测试集
2.  在每个子集中保持原始类别比例

## 优点

1.  保持数据分布的完整性
2.  评估结果更具代表性
3.  对小数据集特别重要

## 缺点

1.  需要知道样本的类别标签
2.  对多标签情况实现复杂

## 典型应用

*   小规模数据集划分
*   多类别分类任务
*   医学研究数据集

## 5. 重要性采样（Importance Sampling）

## 解决的问题

1.  估计稀有事件的概率
2.  降低蒙特卡洛估计的方差

## 实现方式

```math
\mathbb{E}_p[f(x)] \approx \frac{1}{n} \sum_{i=1}^n \frac{p(x_i)}{q(x_i)} f(x_i)
```

其中 `$q(x)$` 是提议分布

## 优点

1.  可以显著降低估计方差
2.  提高对稀有事件的采样效率

## 缺点

1.  需要设计好的提议分布
2.  差的提议分布可能导致估计更差

## 典型应用

*   强化学习中的策略梯度方法
*   贝叶斯推断
*   罕见事件模拟

## 采样方法选择建议

1.  **类别极度不平衡**：SMOTE + 下采样组合
2.  **大规模词汇表**：负采样
3.  **小数据集划分**：分层采样
4.  **强化学习**：重要性采样
5.  **计算资源有限**：下采样

## 高级采样技术（补充）

## 对抗性采样

使用生成对抗网络(GAN)生成合成样本，特别适合处理高度不平衡数据

## 课程学习采样

从简单样本开始，逐步增加难度，模拟人类学习过程

## 核心集采样

选择最能代表数据分布的子集，常用于大规模数据集

需要了解哪种采样方法在特定场景下的实现细节吗？或者想了解如何组合使用这些方法？
