
# 5. 检索策略与算法

## 5.1 实现原理

在RAG系统中，检索（Retrieval）是决定最终答案质量的“上游”关键环节。其核心目标是：根据用户的查询（Query），快速、准确地从海量文档中召回最相关的信息片段。为了实现这一目标，现代RAG系统通常采用多种检索策略和算法，而不仅仅是单一的向量搜索。

### 5.1.1 稀疏检索 vs. 稠密检索

1.  **稀疏检索（Sparse Retrieval）**：
    *   **原理**：基于关键词匹配的传统信息检索方法。它将文本表示为一个高维但大部分元素为零的“稀疏”向量，向量的每一维对应词汇表中的一个词，值通常是该词的某种权重（如TF-IDF或BM25）。
    *   **代表算法**：**BM25 (Best Matching 25)** 是目前最流行和效果最好的稀疏检索算法。它综合考虑了词频（Term Frequency）、逆文档频率（Inverse Document Frequency）和文档长度，来计算查询关键词与文档之间的相关性分数。

        ### BM25算法详解

        BM25是一种基于词袋模型（Bag-of-Words）的排序函数，用于评估文档与查询之间的相关性。它的核心思想是：一个词在文档中出现的频率越高，文档越相关；一个词在整个语料库中出现的频率越低（越稀有），其区分度越大，权重越高；文档越短，其包含某个词的权重相对越高。

        BM25的计算公式如下：

        $$
         \text{Score}(D, Q) = \sum_{i=1}^{n} \text{IDF}(q_i) \cdot \frac{f(q_i, D) \cdot (k_1 + 1)}{f(q_i, D) + k_1 \cdot (1 - b + b \cdot \frac{|D|}{\text{avgdl}})} 
        $$

        其中：
        *   $D$: 待评分的文档。
        *   $Q$: 查询，包含关键词 $q_1, q_2, ..., q_n$。
        *   $f(q_i, D)$: 关键词 $q_i$ 在文档 $D$ 中出现的频率（Term Frequency, TF）。
        *   $|D|$: 文档 $D$ 的长度（通常是词的数量）。
        *   $\text{avgdl}$: 语料库中所有文档的平均长度。
        *   $k_1$: 一个正参数，用于调节词频饱和度。通常取值在1.2到2.0之间。$k_1$ 越大，词频对分数的影响越大。
        *   $b$: 一个参数，用于调节文档长度对分数的影响。通常取值在0到1之间。$b$ 越大，文档长度对分数的影响越大。当 $b=0$ 时，不考虑文档长度；当 $b=1$ 时，完全按照文档长度进行归一化。
        *   $\text{IDF}(q_i)$: 关键词 $q_i$ 的逆文档频率（Inverse Document Frequency）。它衡量一个词在整个语料库中的稀有程度。计算公式通常为：

            $$ \text{IDF}(q_i) = \log \frac{N - n(q_i) + 0.5}{n(q_i) + 0.5} $$

            其中：
            *   $N$: 语料库中的总文档数量。
            *   $n(q_i)$: 包含关键词 $q_i$ 的文档数量。

        **BM25的优点**：
        *   **效果好**：在许多信息检索任务中表现出色，是工业界和学术界广泛使用的基准算法。
        *   **可解释性强**：每个参数和项都有明确的物理意义，易于理解和调试。
        *   **计算效率高**：相比于深度学习模型，BM25的计算成本非常低，适合大规模语料库的快速检索。

        **BM25的局限性**：
        *   **无法理解语义**：它仍然是基于关键词匹配的，无法处理同义词、近义词或更复杂的语义关系。例如，查询“笔记本电脑”无法匹配到包含“laptop”的文档。
        *   **对词形变化敏感**：对于“run”、“running”、“ran”等词形变化，可能需要额外的词干提取或词形还原处理。
        *   **参数调优**：$k_1$ 和 $b$ 参数需要根据具体语料库进行调优，以达到最佳效果。
    *   **优点**：计算速度快，对关键词的匹配精准，可解释性好。
    *   **缺点**：无法理解语义相似性。例如，无法将“笔记本电脑”和“laptop”关联起来。

2.  **稠密检索（Dense Retrieval）**：
    *   **原理**：基于深度学习的语义匹配方法。它使用预训练的Embedding模型将文本和查询都转换为一个低维（如几百维）但所有元素都有值的“稠密”向量。通过计算向量间的相似度（如余弦相似度）来判断语义相关性。
    *   **代表算法**：**DPR (Dense Passage Retriever)** 是一个典型的代表，它使用双编码器（Dual-Encoder）架构，分别独立地编码查询和文档。
    *   **优点**：能够捕捉深层次的语义信息，理解同义词、近义词和上下文关系。
    *   **缺点**：对于关键词的精确匹配有时不如稀疏检索，且计算成本相对较高。

### 5.1.2 混合搜索（Hybrid Search）

*   **原理**：为了结合稀疏检索和稠密检索的优点，混合搜索应运而生。它同时执行两种检索，然后将它们的结果进行融合，得到一个更全面、更准确的排序。
*   **实现方式**：
    1.  **两阶段检索（Two-stage Retrieval / Re-ranking）**：这是最常见的方式。首先，使用速度更快、成本更低的稀疏检索（如BM25）进行“粗排”，从海量文档中快速召回一个较大的候选集（如Top 100）。然后，再使用计算更密集的稠密检索（向量相似度）对这个小得多的候选集进行“精排”，得到最终的Top-K结果。您的 `./rag` 项目中的 `HybridRetrieverManager` 就是采用的这种策略。
    2.  **分数融合（Score Fusion）**：并行执行稀疏检索和稠密检索，然后将两种检索得到的分数通过一个加权公式（如 `final_score = w * bm25_score + (1-w) * vector_score`）进行组合，最后根据融合后的分数进行排序。这需要对两种分数进行归一化处理。

### 5.1.3 相似性搜索算法

在稠密检索的背后，是高效的相似性搜索算法，即近似最近邻（ANN）搜索。它通过构建如 `HNSW` (Hierarchical Navigable Small World) 这样的索引结构，实现在海量向量中进行亚线性时间的快速查找。

## 5.2 所解决的问题

1.  **召回的全面性**：单纯使用稠密检索可能会漏掉一些与查询关键词完全匹配但语义稍远的重要文档。单纯使用稀疏检索则会漏掉所有语义相关但用词不同的文档。混合搜索结合了两者的长处，显著提高了召回的全面性（Recall）。
2.  **排序的准确性**：用户的查询意图是复杂的，有时侧重关键词，有时侧重语义。混合搜索通过两阶段或分数融合的方式，能够更准确地对结果进行排序，将最可能满足用户需求的文档排在最前面，提高了排序的精确率（Precision）。
3.  **效率与成本的平衡**：两阶段的检索策略是一个典型的工程优化。它用低成本的BM25算法完成了90%的粗筛工作，只让高成本的向量模型处理少量最相关的候选集，从而在保证效果的同时，极大地提高了系统的响应速度和降低了计算成本。

## 5.3 核心代码

您的 `rag/retriever.py` 中的 `HybridRetrieverManager` 类完美地实现了“ES粗排 + 向量精排”的混合检索策略。

### 5.3.1 混合检索的入口

`retrieve` 方法是混合检索的总入口，它根据系统配置决定是执行混合检索还是纯向量检索。

```python
# rag/retriever.py

class HybridRetrieverManager:
    def retrieve(self, query: str, ...):
        # ...
        if self.hybrid_mode and self.es_manager:
            # 混合检索模式：ES粗排 + 向量精排
            return self._hybrid_retrieve(query, ...)
        else:
            # 纯向量检索模式
            return self._vector_only_retrieve(query, ...)
```

### 5.3.2 两阶段检索的实现 (`_hybrid_retrieve`)

这个私有方法清晰地展示了“粗排-精排”的流程。

```python
# rag/retriever.py

def _hybrid_retrieve(self, query: str, ...):
    # 1. 查询扩展 (Query Expansion)
    expanded_query = self.query_expander.expand_query(query).expanded_query
    
    # 2. ES粗排：使用Elasticsearch进行关键词检索，获取候选集
    es_results = self.es_manager.search_documents(expanded_query, size=es_candidates)
    
    if not es_results:
        # ... 回退到纯向量检索
    
    # 3. 向量精排：对ES返回的候选集进行向量重排序
    reranked_results = self._vector_rerank(query, es_results, top_k)
    
    return reranked_results
```

### 5.3.3 向量重排序与分数融合 (`_vector_rerank`)

这个方法是精排的核心，它计算向量相似度并融合分数。

```python
# rag/retriever.py

def _vector_rerank(self, query: str, es_results: List[SearchResult], top_k: int):
    # ...
    query_embedding = self.embedding_manager.embed_query(query)
    
    rerank_candidates = []
    for es_result in es_results:
        # 为每个ES结果计算向量相似度
        doc_embedding = self.embedding_manager.embed_documents([es_result.content])[0]
        vector_score = self._cosine_similarity(query_embedding, doc_embedding)
        
        # 计算组合分数 (加权平均)
        es_weight = 0.3
        vector_weight = 0.7
        combined_score = es_weight * es_result.score + vector_weight * vector_score
        
        rerank_candidates.append(RetrievalResult(
            ...,
            combined_score=combined_score,
            ...
        ))

    # 按组合分数进行最终排序
    rerank_candidates.sort(key=lambda x: x.combined_score, reverse=True)
    
    return rerank_candidates[:top_k]
```

## 5.4 实际工程中的应用

*   **多路召回与融合**：在大型搜索引擎或推荐系统中，通常会设计更为复杂的“多路召回”架构。除了BM25和向量检索，可能还会有基于用户行为、地理位置、时间衰减等多种召回策略。各路召回的结果会进入一个统一的排序层（Learning to Rank, LTR），由一个机器学习模型来决定最终的排序，而不仅仅是简单的加权平均。
*   **动态权重调整**：分数融合中的权重（如代码中的 `es_weight` 和 `vector_weight`）可以不是固定的，而是根据查询的类型动态调整。例如，对于包含很多专有名词的查询，可以动态增加BM25的权重；对于更口语化、更抽象的查询，则可以增加向量相似度的权重。
*   **ColBERT等后期交互模型**：除了DPR这种双编码器模型，还有更先进的如ColBERT这样的“后期交互”（Late Interaction）模型。它不是将整个文档压缩成一个向量，而是为文档中的每个Token都生成一个向量。在检索时，它会计算查询中每个Token的向量与文档中所有Token向量的最大相似度，然后求和。这种方式能更精细地捕捉词级别的相关性，通常能取得比DPR更好的效果，但计算成本也更高，常被用在精排阶段。

## 5.5 面试题及答案

**1. 什么是稀疏检索和稠密检索？它们各有什么优缺点？**

*   **答案**：
    *   **稀疏检索**（以BM25为代表）是基于关键词匹配的传统方法。它将文本表示为词汇表大小的高维稀疏向量。
        *   **优点**：速度快，对关键词的字面匹配非常精准，可解释性强。
        *   **缺点**：无法理解语义，比如无法识别同义词，对用户输入的措辞非常敏感。
    *   **稠密检索**（以向量相似性搜索为代表）是基于深度学习的方法。它使用Embedding模型将文本映射为低维的稠密语义向量。
        *   **优点**：能够理解文本的深层语义，可以匹配意思相近但用词不同的文本，鲁棒性更好。
        *   **缺点**：对于某些需要精确关键词匹配的场景（如产品型号、人名）可能不如稀疏检索，且计算和存储成本更高。

**2. 什么是混合搜索（Hybrid Search）？为什么它在RAG中通常比单一的检索方法效果更好？**

*   **答案**：
    *   **混合搜索** 是一种将稀疏检索（如BM25）和稠密检索（向量搜索）相结合的策略。
    *   **效果更好的原因**：它能博采众长，实现优势互补。稀疏检索保证了对关键词的精准匹配，弥补了稠密检索有时会忽略字面信息的不足；而稠密检索则负责理解语义，弥补了稀疏检索无法处理同义词、近义词的缺陷。通过将两者的结果结合起来，混合搜索能够提供一个既包含关键词精确匹配，又包含语义相关匹配的、更全面、更准确的召回结果，从而显著提升了RAG系统的整体性能。

**3. 请描述一下“粗排 + 精排”（Two-stage Retrieval）的检索流程。**

*   **答案**：这是一个在工业界非常常见的两阶段检索策略：
    1.  **第一阶段：粗排（Recall/Candidate Generation）**：
        *   **目标**：快速、低成本地从海量的全量文档库中，召回一个相对较大但 manageable 的候选集（例如，100到1000个文档）。
        *   **方法**：通常使用计算效率高的算法，如稀疏检索的 **BM25**。
    2.  **第二阶段：精排（Ranking/Re-ranking）**：
        *   **目标**：对粗排阶段得到的候选集进行更精确、更复杂的排序，以确定最终返回给用户的Top-K个结果。
        *   **方法**：使用计算成本更高但效果更好的算法。在RAG中，通常是计算查询与候选文档之间的 **向量余弦相似度**。有时还会使用更复杂的交叉编码器（Cross-Encoder）模型或机器学习排序模型（LTR）来进行重排序。
    *   这种分阶段的方法，是在 **效果、成本和延迟** 之间做出的一个非常高效的工程权衡。

**4. 在你的项目中，混合搜索是如何实现的？两种检索的分数是如何融合的？**

*   **答案**：（需要结合自己的项目来回答，以下是基于 `./rag` 项目的示例）
    *   在我的项目中，混合搜索是通过 `HybridRetrieverManager` 类实现的，采用的是“**Elasticsearch粗排 + 向量精排**”的两阶段策略。
    *   首先，用户的查询会经过 `es_manager.search_documents` 方法，利用Elasticsearch内置的BM25算法进行关键词检索，快速召回一个候选集。
    *   然后，在 `_vector_rerank` 方法中，系统会遍历这个候选集中的每一个文档，调用 `embedding_manager` 为它们计算向量，并计算与查询向量的余弦相似度（`vector_score`）。
    *   **分数融合**是通过一个简单的 **加权平均** 公式实现的：`combined_score = 0.3 * es_result.score + 0.7 * vector_score`。这里我给予了向量相似度更高的权重（0.7），因为我认为语义相关性在我的应用中更重要。最后，所有候选文档会根据这个 `combined_score` 进行降序排序，返回Top-K的结果。这种方式简单有效地结合了两种信号。
