
# 11. 高级RAG技术：自适应RAG

## 11.1 实现原理

标准RAG流程（检索->生成）虽然有效，但其过程是固定的、线性的。高级RAG技术，特别是自适应RAG（Adaptive RAG），引入了动态性、决策和迭代循环，使系统能够根据问题的具体情况，智能地调整其信息检索和答案生成的策略。这标志着RAG从一个固定的“流水线”向一个更智能的“工作流”演进。

### 11.1.1 迭代式RAG（Iterative RAG）

*   **核心思想**：对于复杂问题，一次检索可能不足以收集到所有必要的信息。迭代式RAG将问答过程分解为多个“检索-生成”的循环，逐步深入或扩展，直到找到满意的答案。
*   **实现原理**：
    1.  **问题分解（Query Decomposition）**：当面对一个复杂问题时（如“对比A和B的优缺点”），系统首先将其分解为多个子问题（“A的优点是什么？”、“B的优点是什么？”、“A的缺点是什么？”...）。
    2.  **循环检索**：系统依次对每个子问题执行RAG流程，检索相关信息。
    3.  **知识累积**：在每个循环中，新检索到的知识会被累积起来。
    4.  **最终综合**：当所有子问题都得到解答后，系统会将所有累积的知识和原始问题一起，交给LLM进行一次最终的综合，生成一个全面的答案。
    *   另一种迭代方式是 **查询重构（Query Rewriting）**，即系统进行第一次检索后，根据初步结果，由LLM重写一个更好的、更精确的查询，然后进行第二次检索，如此往复。

### 11.1.2 自我修正/反思RAG（Self-Correcting / Self-Reflective RAG）

*   **核心思想**：赋予RAG系统自我评估和修正的能力。在生成答案后，系统会增加一个“反思”步骤，来评判检索到的文档是否相关、生成的答案是否准确，并根据评判结果决定是否需要修正。
*   **实现原理**（以Self-RAG为例）：
    1.  **按需检索**：LLM首先判断用户问题是否需要进行检索。对于常识性问题（如“法国的首都是哪里？”），它可以直接回答，无需启动RAG流程，从而节省资源。
    2.  **生成“反思Token”**：在检索和生成过程中，LLM被训练得可以生成一些特殊的“反思Token”，用来评估中间产物的质量。
        *   `[Retrieve]`：判断是否需要检索。
        *   `[IsRelevant]`：判断检索到的每个文档块是否与问题相关。
        *   `[IsSupported]`：判断自己生成的每一句话，是否能被检索到的上下文所支持。
    3.  **决策与修正**：根据这些反思Token的评估结果，系统可以动态决策。如果所有文档块都被判断为不相关，系统会重新生成查询并再次检索。如果生成的某句话被判断为无证据支持，系统会尝试重新措辞或从上下文中寻找其他信息来回答。

### 11.1.3 Agentic RAG

*   **核心思想**：这是目前最前沿、最强大的RAG形态。它将RAG系统构建为一个或多个自主的智能体（Agent）。这个Agent不仅能执行检索，还拥有多种工具（Tools），并具备规划（Planning）、记忆（Memory）和决策（Decision-making）能力。
*   **实现原理**：
    1.  **智能体（Agent）**：核心是一个由LLM驱动的控制器（Controller）。
    2.  **工具箱（Toolbox）**：Agent可以调用多种工具，例如：
        *   `RAG检索器`：用于从内部知识库检索。
        *   `Web搜索引擎`：用于获取最新的外部信息。
        *   `计算器`：用于数学计算。
        *   `代码解释器`：用于执行代码、分析数据。
        *   `数据库查询API`：用于从结构化数据库中获取数据。
    3.  **ReAct框架（Reason + Act）**：Agent通常遵循一个“思考-行动”的循环框架。
        *   **思考（Reason）**：LLM分析用户的总目标，将其分解成一系列可执行的步骤，并决定当前应该使用哪个工具。
        *   **行动（Act）**：执行选定的工具（如调用RAG检索器）。
        *   **观察（Observe）**：获取工具返回的结果。
        *   LLM根据观察到的结果，再次进入“思考”环节，规划下一步行动，直到最终目标完成。

## 11.2 所解决的问题

1.  **处理复杂和多跳（Multi-hop）问题**：标准RAG难以回答需要结合多个知识点进行推理的问题。迭代式RAG和Agentic RAG通过问题分解和多步推理，能够很好地解决这类问题。
2.  **提升答案的可靠性和事实性**：自我修正RAG通过引入“反思”和“事实核查”步骤，显著降低了幻觉，让答案的每一句话都有据可查，极大地提升了系统的可信度。
3.  **应对开放域和动态信息**：Agentic RAG通过赋予系统使用网络搜索等外部工具的能力，打破了RAG对内部静态知识库的依赖，使其能够回答关于最新事件的提问。
4.  **任务处理的灵活性和通用性**：Agentic RAG将RAG从一个“问答系统”提升为一个“任务处理系统”。它不再局限于回答问题，而是可以根据用户指令，自主规划并执行一系列复杂操作，如“帮我分析这份财报，总结关键指标，并生成一份PPT大纲”。

## 11.3 核心代码

自适应RAG更多的是一种架构思想和工作流的实现，而不是单一的、具体的代码片段。它通常需要借助LangChain、LlamaIndex等框架中实现的Agent、Tool和Router等概念来构建。在您当前的项目中，虽然没有直接实现这些高级RAG，但可以设想如何对其进行扩展。

**设想：将您当前项目扩展为迭代式RAG**

可以修改 `RAGChain` 的 `query` 方法：

```python
# 伪代码，示意如何扩展

class AdvancedRAGChain(RAGChain):
    def iterative_query(self, question: str, max_iterations: int = 3):
        final_answer = ""
        accumulated_context = ""
        current_question = question

        for i in range(max_iterations):
            print(f"--- Iteration {i+1} ---")
            
            # 1. 使用当前问题进行检索
            retrieval_results = self.retriever.retrieve(current_question)
            if not retrieval_results:
                break # 如果某一步检索不到，就终止

            # 2. 累积上下文
            new_context = "\n\n".join([res.document.page_content for res in retrieval_results])
            accumulated_context += "\n\n" + new_context

            # 3. 构建让LLM判断是否继续的Prompt
            check_prompt = f"""Context:
{accumulated_context}

Question: {question}

Based on the context, is the question fully answered? If yes, say 'Yes'. If not, formulate a follow-up question to find the missing information."""
            
            # 4. 让LLM进行反思和决策
            reflection = self.llm.generate(check_prompt)

            if reflection.strip().lower() == 'yes':
                break # 如果LLM认为问题已解决，则跳出循环
            else:
                current_question = reflection # 否则，使用LLM生成的新问题进行下一轮迭代

        # 5. 最后，使用所有累积的上下文进行最终的答案生成
        final_prompt = self._build_prompt(question, accumulated_context)
        final_answer = self.llm.generate(final_prompt)
        
        return final_answer
```

## 11.4 实际工程中的应用

*   **AI研究助手**：Agentic RAG被广泛用于构建AI研究助手。用户给出一个研究课题，Agent可以自动上网搜索论文、阅读PDF、总结要点、分析数据，并最终生成一份研究报告。
*   **复杂的客户支持**：对于需要查询订单状态、分析用户使用记录、并执行退款操作的复杂客服请求，Agentic RAG可以依次调用数据库API、日志系统和支付API来一步步完成整个流程。
*   **自动化数据分析**：用户可以用自然语言提出分析需求（“帮我分析上个季度的销售数据，找出增长最快的产品类别”），Agentic RAG可以调用代码解释器工具，编写并执行Python代码（如Pandas, Matplotlib）来完成数据分析和可视化。

## 11.5 面试题及答案

**1. 什么是自适应RAG（Adaptive RAG）？它相比于标准RAG有什么优势？**

*   **答案**：
    *   **自适应RAG** 是一类高级RAG方法的总称，它指的是RAG系统能够根据问题的具体情况，动态地、智能地调整其检索和生成策略，而不是遵循一个固定的、线性的流程。
    *   **优势**：
        1.  **效率更高**：它可以判断何时不需要检索（例如回答常识性问题），从而避免不必要的计算开销。
        2.  **效果更好**：通过迭代检索、问题分解或自我修正，它能处理更复杂的问题，并生成更可靠、更准确的答案。
        3.  **能力更强**：特别是Agentic RAG，通过引入工具使用和规划能力，将RAG从一个“问答工具”提升为一个能完成复杂任务的“自主代理”，极大地扩展了其应用范围。

**2. 请解释迭代式RAG（Iterative RAG）的工作原理，并举一个它适合处理的例子。**

*   **答案**：
    *   **工作原理**：迭代式RAG通过执行多次“检索-生成”循环来处理复杂问题。在每个循环中，它可能会根据之前的结果来重写和优化查询（Query Rewriting），或者将一个大问题分解成多个子问题并依次解决（Query Decomposition），同时不断累积检索到的知识，直到问题被完全解答。
    *   **例子**：用户提问：“请比较一下大模型微调（Fine-tuning）和RAG在知识更新和成本方面的优缺点。”
        *   **第一次迭代**：系统可能先检索“RAG的优缺点”。
        *   **第二次迭代**：系统接着检索“大模型微调的优缺点”。
        *   **第三次迭代**：系统可能再检索“RAG与微调的成本对比”。
        *   **最终生成**：最后，系统将这三次迭代检索到的所有信息综合起来，生成一个全面的、结构化的对比分析答案。

**3. 什么是Agentic RAG？它和普通的RAG最核心的区别是什么？**

*   **答案**：
    *   **Agentic RAG** 是一种将RAG系统构建为自主智能体（Agent）的先进架构。这个Agent由一个LLM作为“大脑”，并被赋予了规划、记忆和使用多种外部工具的能力。
    *   **核心区别**：最核心的区别在于 **“工具使用（Tool Use）”** 和 **“自主规划（Autonomous Planning）**。
        *   **普通RAG** 的能力边界被其内部的静态知识库所限定，它本质上是一个“封闭世界”的问答器。
        *   **Agentic RAG** 则是一个“开放世界”的任务处理器。它不仅能从内部知识库检索，还能根据需要自主决定使用 **外部工具**，如进行实时网页搜索、执行代码、查询API等。它能为了完成一个目标而 **自主地规划步骤**，动态地选择和组合工具，这是普通RAG完全不具备的能力。

**4. Self-RAG是如何实现自我修正的？它引入了什么关键机制？**

*   **答案**：
    *   Self-RAG通过让LLM在生成过程中进行 **“自我反思（Self-Reflection）”** 来实现自我修正。
    *   **关键机制**：它引入了特殊的 **“反思Token”（Reflection Tokens）**。LLM被特殊训练，使其在生成过程中，能够按需输出这些Token来评估自己的工作状态。
        *   例如，在检索后，它会为每个文档块生成一个 `[IsRelevant]` Token来判断其相关性。如果判断为不相关，它就可以放弃这个文档块。
        *   在生成答案的每一句话后，它会生成一个 `[IsSupported]` Token来判断这句话是否能被检索到的上下文所支持。如果不支持，就意味着可能产生了幻觉，模型会尝试撤回这句话并重新生成。
    *   通过这种“边生成、边评估、边修正”的机制，Self-RAG能够显著提高答案的事实性和可靠性。

```