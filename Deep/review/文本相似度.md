文本相似度计算是NLP中的核心任务，广泛应用于搜索、去重、推荐等场景。以下是主流方法的原理、公式、应用及优缺点对比：

***

## **一、传统统计方法**

### 1. **余弦相似度（TF-IDF向量化）**

*   **原理**：将文本表示为词频向量，计算向量夹角余弦值
*   **公式**：
    ```math
    \text{sim}(A,B) = \frac{\sum_{i=1}^n A_i B_i}{\sqrt{\sum_{i=1}^n A_i^2} \sqrt{\sum_{i=1}^n B_i^2}}
    ```
    *   其中 `$A_i$`, `$B_i$` 是TF-IDF权重：
    ```math
    \text{TF-IDF}(t,d) = \text{TF}(t,d) \times \log\left(\frac{N}{\text{DF}(t)}\right)
    ```
*   **应用场景**：
    *   文档检索（如搜索引擎）
    *   简单文本分类特征工程
*   **优点**：
    *   计算高效（适合大规模数据）
    *   可解释性强
*   **缺点**：
    *   忽略词序和语义（"猫追狗" vs "狗追猫"得分相同）
    *   无法处理OOV词（未登录词）

### 2. **Jaccard相似度**

*   **原理**：计算词集合的交并比
*   **公式**：
    ```math
    J(A,B) = \frac{|A \cap B|}{|A \cup B|}
    ```
*   **应用场景**：
    *   短文本去重（如新闻标题查重）
    *   关键词快速匹配
*   **优点**：
    *   计算速度极快
*   **缺点**：
    *   仅适用于词级别匹配

***

## **二、词嵌入方法**

### 1. **Word2Vec平均向量**

*   **原理**：对词向量取平均后计算相似度
*   **公式**：
    ```math
    \text{vec}(text) = \frac{1}{n}\sum_{i=1}^n \text{Word2Vec}(w_i)
    ```
*   **应用场景**：
    *   社交媒体文本相似度（如推特话题聚类）
*   **优点**：
    *   捕捉部分语义关系（如"国王"-"王后"≈"男人"-"女人"）
*   **缺点**：
    *   词义消歧不足（"苹果"公司 vs 水果无法区分）
    *   静态向量（一词一义）

### 2. **GloVe全局向量**

*   **原理**：基于全局词共现矩阵的降维表示
*   **公式**：
    ```math
    J = \sum_{i,j=1}^V f(X_{ij})(w_i^T \tilde{w}_j + b_i + \tilde{b}_j - \log X_{ij})^2
    ```
*   **应用场景**：
    *   学术论文相似度分析
*   **优点**：
    *   更好利用全局统计信息
*   **缺点**：
    *   依然无法处理多义词

***

## **三、深度学习方法**

### 1. **BERT句向量（\[CLS]或均值池化）**

*   **原理**：用Transformer编码器生成上下文感知的句向量
*   **公式**：
    ```math
    h_{\text{[CLS]}} = \text{BERT}(text)[0]
    ```
    或均值池化：
    ```math
    h_{\text{mean}} = \frac{1}{n}\sum_{i=1}^n \text{BERT}(text)[i]
    ```
*   **应用场景**：
    *   法律文书相似度判定
    *   客服问答匹配
*   **优点**：
    *   动态词义（解决多义词问题）
    *   捕捉深层语义关系
*   **缺点**：
    *   计算成本高（需GPU加速）
    *   句向量存在各向异性问题

### 2. **Sentence-BERT（SBERT）**

*   **原理**：对BERT进行孪生网络微调，优化相似度任务
*   **训练目标**（如余弦相似度损失）：
    ```math
    \text{loss} = ||\cos(h_a, h_p) - 1||^2 + ||\cos(h_a, h_n)||^2
    ```
    其中`$h_p$`为正样本，`$h_n$`为负样本
*   **应用场景**：
    *   大规模语义搜索（如FAQ匹配）
    *   跨语言相似度计算
*   **优点**：
    *   相似度计算仅需0.1ms/句（预计算后）
    *   在STS基准上Spearman相关度达0.85+
*   **缺点**：
    *   需要标注数据微调

### 3. **SimCSE对比学习**

*   **原理**：通过Dropout构造正样本，无监督提升句向量质量
*   **训练目标**：
    ```math
    \mathcal{L} = -\log \frac{e^{\text{sim}(h_i, h_i^+)/\tau}}{\sum_{j=1}^N e^{\text{sim}(h_i, h_j)/\tau}}
    ```
    其中`$\tau$`为温度系数，`$h_i^+$`是同句不同Dropout的结果
*   **应用场景**：
    *   无监督文本聚类
    *   低资源语言相似度计算
*   **优点**：
    *   无需标注数据
    *   解决BERT句向量各向异性
*   **缺点**：
    *   对领域分布敏感

***

## **四、前沿方法（2024）**

### 1. **大语言模型（LLM）嵌入**

*   **技术**：用GPT-4等模型生成文本描述再计算相似度
*   **示例流程**：
    1.  提示工程：`"请用20字描述以下文本的核心语义：" + text`
    2.  对生成的描述用传统方法计算相似度
*   **优势**：
    *   理解隐含语义（如讽刺、隐喻）
*   **局限**：
    *   API调用成本高

### 2. **多模态相似度**

*   **方法**：CLIP等模型联合处理文本和图像
*   **公式**：
    ```math
    \text{sim}(text, image) = \text{CLIP}_{\text{text}}(t) \cdot \text{CLIP}_{\text{image}}(i)
    ```
*   **应用**：
    *   电商商品描述与图片匹配
    *   视频字幕检索

***

## **五、方法对比与选型建议**

| **方法**      | **适合场景**  | **速度**     | **准确度**    | **所需资源**    |
| ----------- | --------- | ---------- | ---------- | ----------- |
| TF-IDF + 余弦 | 大规模文档去重   | ⚡️⚡️⚡️⚡️⚡️ | ⭐️⭐️       | CPU单机       |
| Word2Vec平均  | 社交媒体短文本聚类 | ⚡️⚡️⚡️⚡️   | ⭐️⭐️⭐️     | 预训练词向量      |
| BERT句向量     | 专业领域精细匹配  | ⚡️⚡️       | ⭐️⭐️⭐️⭐️   | GPU + 预训练模型 |
| SBERT       | 语义搜索/推荐系统 | ⚡️⚡️⚡️     | ⭐️⭐️⭐️⭐️⭐️ | 标注数据 + 微调   |
| SimCSE      | 无监督跨语言相似度 | ⚡️⚡️⚡️     | ⭐️⭐️⭐️⭐️   | 无监督训练       |

**代码示例（SBERT相似度计算）**：

```python
from sentence_transformers import SentenceTransformer
model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

sentences = ["猫坐在垫子上", "一只猫咪在毯子上"]
embeddings = model.encode(sentences)
similarity = embeddings[0] @ embeddings[1].T  # 余弦相似度
print(similarity)  # 输出0.92（相似度得分）
```

***

## **六、评估指标**

1.  **人工评估**：
    *   相关性评分（1-5分Likert量表）
2.  **自动评估**：
    *   **SemEval STS任务**：计算系统得分与人工评分的Pearson/Spearman相关性
    *   **检索任务指标**：Recall\@k, MRR（Mean Reciprocal Rank）

***

根据具体需求选择方法：追求效率选TF-IDF，要求精度用SBERT，无监督场景尝试SimCSE，多模态需求考虑CLIP。

余弦相似度（Cosine Similarity）是通过计算两个向量的夹角余弦值来衡量它们的相似度，广泛应用于文本、图像等数据的相似性比较。以下是其**计算原理、步骤、应用及示例**的详细说明：

***

## **一、数学原理**

给定两个向量 **A** 和 **B**，余弦相似度的计算公式为：

```math
\text{cosine-sim}(A, B) = \frac{A \cdot B}{\|A\| \cdot \|B\|} = \frac{\sum_{i=1}^n A_i B_i}{\sqrt{\sum_{i=1}^n A_i^2} \cdot \sqrt{\sum_{i=1}^n B_i^2}}
```

*   **分子**：向量 **A** 和 **B** 的点积（对应元素乘积之和）
*   **分母**：向量 **A** 和 **B** 的欧几里得范数（模长）的乘积
*   **输出范围**：\[-1, 1]，但在文本处理中（因TF-IDF等非负权重），通常为 \[0, 1]，值越大表示越相似。

***

## **二、计算步骤（以文本相似度为例）**

### **1. 文本向量化**

将文本转换为数值向量，常用方法：

*   **TF-IDF**：统计词频并加权
*   **词嵌入**（Word2Vec/GloVe）：取词向量平均值
*   **BERT嵌入**：使用预训练模型生成句向量

**示例文本**：

*   文本1：`"猫 喜欢 吃 鱼"`
*   文本2：`"狗 喜欢 吃 肉"`

### **2. 构建向量**

假设词典为 `["猫", "喜欢", "吃", "鱼", "狗", "肉"]`，采用\*\*词频（TF）\*\*向量化：

*   文本1向量 **A**：`[1, 1, 1, 1, 0, 0]`
*   文本2向量 **B**：`[0, 1, 1, 0, 1, 1]`

### **3. 计算余弦相似度**

*   **点积**：\
    `A·B = (1×0) + (1×1) + (1×1) + (1×0) + (0×1) + (0×1) = 2`
*   **向量模长**：\
    `‖A‖ = √(1² + 1² + 1² + 1²) = 2`\
    `‖B‖ = √(1² + 1² + 1² + 1²) = 2`
*   **余弦值**：\
    `cosθ = 2 / (2 × 2) = 0.5`

***

## **三、Python代码实现**

### **1. 基于NumPy**

```python
import numpy as np

def cosine_similarity(a, b):
    dot_product = np.dot(a, b)
    norm_a = np.linalg.norm(a)
    norm_b = np.linalg.norm(b)
    return dot_product / (norm_a * norm_b)

# 示例向量
A = np.array([1, 1, 1, 1, 0, 0])
B = np.array([0, 1, 1, 0, 1, 1])
print(cosine_similarity(A, B))  # 输出 0.5
```

### **2. 结合TF-IDF（Scikit-learn）**

```python
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

corpus = ["猫 喜欢 吃 鱼", "狗 喜欢 吃 肉"]
vectorizer = TfidfVectorizer(tokenizer=lambda x: x.split())
tfidf_matrix = vectorizer.fit_transform(corpus)

# 计算所有文档间的余弦相似度
similarity_matrix = cosine_similarity(tfidf_matrix)
print(similarity_matrix[0][1])  # 输出 0.5
```

***

## **四、应用场景**

1.  **文本检索**：
    *   搜索引擎返回与查询最相似的文档（如Google的网页排名）。
2.  **推荐系统**：
    *   计算用户兴趣向量与商品描述的相似度（如电商推荐）。
3.  **聚类分析**：
    *   合并相似文本（如新闻话题聚合）。
4.  **跨模态匹配**：
    *   图像与文本的相似度（如CLIP模型）。

***

## **五、优缺点分析**

| **优点**             | **缺点**                      |
| ------------------ | --------------------------- |
| 1. 不受向量长度影响（适合长文本） | 1. 忽略词序（"猫追狗" vs "狗追猫"得分相同） |
| 2. 计算高效（线性复杂度）     | 2. 依赖向量化质量（如TF-IDF无法捕捉语义）   |
| 3. 结果可解释（值域明确）     | 3. 需归一化处理（否则可能偏向长文档）        |

***

## **六、改进方向**

1.  **结合语义信息**：
    *   使用BERT等模型生成句向量替代TF-IDF。
2.  **引入词序特征**：
    *   在向量化时加入n-gram或位置编码。
3.  **各向异性修正**：
    *   对向量进行Whitening处理（如SimCSE）。

***

## **七、与其他相似度指标对比**

| **指标**        | **特点**   | **适用场景**    |
| ------------- | -------- | ----------- |
| **欧氏距离**      | 受向量长度影响大 | 需要绝对距离的场景   |
| **Jaccard**   | 仅考虑词集合重叠 | 短文本/关键词快速匹配 |
| **Pearson相关** | 衡量线性相关性  | 数值型特征分析     |

余弦相似度因其**长度不变性**和**计算效率**，成为文本相似度计算的基准方法，但需结合任务需求选择优化策略。
